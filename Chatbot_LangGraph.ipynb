{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CPt1tJQKKM2m",
        "outputId": "5cba5787-7067-484a-c61e-3c54179ac155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.8)\n",
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.11/dist-packages (0.3.2)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.11/dist-packages (0.3.43)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.63)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.26)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.2)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.70)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.5)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain_groq) (0.26.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith) (3.10.18)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.13.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph langchain_groq langsmith langchain langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "groq_api_key=userdata.get('Groq_api_key')"
      ],
      "metadata": {
        "id": "XMPd5_jTKZhP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "llm = ChatGroq(groq_api_key=groq_api_key,\n",
        "               model_name=\"qwen-qwq-32b\")"
      ],
      "metadata": {
        "id": "FOXZdF-_MBxc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.graph import StateGraph,START,END"
      ],
      "metadata": {
        "id": "Hz-JpLMMMsjW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class state(TypedDict):\n",
        "  message:Annotated[list, add_messages]\n",
        "\n",
        "graph_builder=StateGraph(state)"
      ],
      "metadata": {
        "id": "LX5q0DPSNPwP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72hFPcaROlX6",
        "outputId": "ae70c69a-10a8-42f3-c098-392f476074d5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7826daa03450>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state:state):\n",
        "  return {\"message\":llm.invoke(state['message'])}"
      ],
      "metadata": {
        "id": "WxXZP7RsOvVv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_node(\"chatbot\",chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0YdQqeoPJyn",
        "outputId": "1e47b1c2-6b9d-4967-b7f1-fdbd7fce575c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7826daa03450>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfotB0pfPdg6",
        "outputId": "b7006236-d112-444c-af5e-24fe5ecf7922"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7826daa03450>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START,\"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\",END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX0MbYdLPjxY",
        "outputId": "0fec424a-a2fb-4306-e44c-55839ee5bb86"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7826daa03450>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.compile()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "-yICpaT1P2F2",
        "outputId": "b2cafc31-c309-40ea-ff83-ffadc2a3025f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x7826d9cee550>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph=graph_builder.compile()"
      ],
      "metadata": {
        "id": "QkA6aIyBQRVR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input=input(\"user :\")\n",
        "  if user_input.lower() in ['quit','q']:\n",
        "    print(\"Good bye ..\")\n",
        "    break\n",
        "  for event in graph.stream({'message':('user', user_input)}):\n",
        "    print(event.values())\n",
        "    for value in event.values():\n",
        "      print(value['message'])\n",
        "      print('Assisstant:',value['message'].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvZTOWZSRFy7",
        "outputId": "a12eaadb-bbd2-4c1b-bf67-0df46271fd16"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user :LAnggraph\n",
            "dict_values([{'message': AIMessage(content='\\n<think>\\nOkay, the user mentioned \"LAnggraph.\" I think they might be referring to LangGraph, which I know is related to LangChain. Let me confirm that first. LangChain is a framework for developing applications using LLMs. LangGraph, perhaps, is a tool within LangChain for visualizing the structure of the chains or the data flow? I should check the official documentation or look up recent updates to see if there\\'s a specific tool called LangGraph.\\n\\nAlternatively, maybe it\\'s a typo or a less commonly known term. Let me think of possibilities. Could it be a part of the LangChain library that handles graph-based data structures or workflows? Or maybe it\\'s a tool for creating graphs of model interactions? I\\'ve heard of tools like LLMs in a graph format for knowledge graphs, but I\\'m not sure.\\n\\nWait, maybe LangGraph is a visualization tool for LangChain chains. The user might be asking how to use it or what it does. Since LangChain allows creating chains of LLMs and other components, visualizing these chains could help in debugging or understanding the flow. If that\\'s the case, I should explain how to use LangGraph, perhaps through code examples or by directing them to the relevant documentation.\\n\\nAlternatively, if LangGraph isn\\'t a standard part of LangChain, maybe the user is referring to a different project. I should consider that possibility as well. Maybe a quick search would help, but since I can\\'t browse the internet, I have to rely on existing knowledge. I recall that LangChain has a Chains module, and sometimes they mention visualization. There\\'s also a tool called \"Trace\" in LangChain for tracing runs, which might be related to graphing.\\n\\nLet me structure the response. First, clarify that LangGraph might be part of LangChain\\'s visualization tools. Then explain LangChain\\'s purpose, mention Chains, and then discuss how to visualize them using LangChain\\'s built-in features or third-party tools. If there\\'s no LangGraph, perhaps suggest alternatives like using graphviz or generating DOT files from the chain structure.\\n\\nWait, maybe the user is confused between LangChain and LangGraph, thinking they\\'re separate. I should correct that LangChain is the main framework, and visualization tools like graphviz can be used alongside it. Alternatively, maybe they are referring to a specific tool called LangGraph that I\\'m not aware of. In that case, I should mention that it\\'s not part of the standard LangChain package and suggest checking the LangChain documentation or community resources for more info.\\n\\nI should also consider if the user is looking for an explanation of what LangGraph is. If it\\'s a tool for creating knowledge graphs with LLMs, then I can explain how to use LangChain with knowledge graphs. But without more context, it\\'s a bit tricky. The best approach is to outline possible scenarios: LangGraph as part of LangChain\\'s visualization, a separate tool, or a misunderstanding. Then provide general guidance on visualizing workflows, knowledge graphs, or debugging chains in LangChain.\\n\\nAlso, include code examples if possible. For instance, showing how to create a chain and then visualize its steps. Maybe using matplotlib or networkx to draw the graph structure of a chain. Alternatively, using LangChain\\'s trace and view it in the UI. Let me think of a sample code snippet for a simple chain and then a way to represent it as a graph.\\n\\nAlternatively, check if there\\'s a method in LangChain to export the chain structure to a graph format. The user might be looking for that. If not, suggest alternatives. Make sure to mention that if they have a specific question or task related to LangGraph, they should provide more details so I can assist better.\\n\\nAnother angle: Maybe \"LangGraph\" refers to a specific implementation or a fork of LangChain with graph capabilities. Since I can\\'t verify, I should stick to known information and suggest possible approaches. Conclude by inviting them to clarify if needed.\\n</think>\\n\\nIt seems like you might be referring to **LangChain**, a framework for developing applications with Large Language Models (LLMs), or possibly a visualization tool related to it. The term \"LangGraph\" isn’t a widely recognized term in the context of LangChain, but I can help clarify how to work with **graphs or visualizations** in the LangChain ecosystem.\\n\\n---\\n\\n### **If you meant \"LangChain\":**\\nLangChain is a library for developing applications using LLMs, with a focus on structuring workflows, managing data, and building complex LLM pipelines. It includes tools like **chains**, **agents**, and **memory**, which can be visualized to understand their flow.\\n\\n---\\n\\n### **Visualizing Chains (LangChain)**\\nLangChain itself doesn’t have a built-in tool called \"LangGraph,\" but you can visualize the structure of **chains** (sequences of LLM operations) using standard visualization libraries. Here’s how:\\n\\n#### **1. Using `graphviz` for workflow diagrams:**\\nYou can manually create a graph of your LangChain chain using tools like `graphviz` (DOT language) to represent nodes (LLM steps) and edges (data flow).\\n\\n**Example:**\\n```python\\nfrom graphviz import Digraph\\n\\ndot = Digraph(comment=\\'LangChain Workflow\\')\\n\\n# Add nodes for each component in your chain\\ndot.node(\\'LLM1\\', \\'Text Generation\\')\\ndot.node(\\'LLM2\\', \\'Summarization\\')\\ndot.node(\\'Output\\', \\'Final Output\\')\\n\\n# Connect components\\ndot.edge(\\'LLM1\\', \\'LLM2\\', label=\\'Input Data\\')\\ndot.edge(\\'LLM2\\', \\'Output\\', label=\\'Summary\\')\\n\\nprint(dot.source)\\ndot.render(\\'chain_graph.dot\\', view=True)\\n```\\n\\n#### **2. Using LangChain’s built-in tracing:**\\nLangChain provides a `Tracer` class to log and trace the execution of chains. You can then use the trace data to reconstruct the workflow graphically.\\n\\n```python\\nfrom langchain import tracing\\nfrom langchain.chains import LLMChain\\nfrom langchain.llms import OpenAI\\n\\n# Start tracing\\ntracing.set_handler(tracing.FileHandler())\\n\\n# Create a simple chain\\nllm = OpenAI(temperature=0.7)\\nchain = LLMChain(llm=llm, prompt=prompt_template)\\n\\n# Run the chain and log steps\\nchain.run(\"Input text\")\\n\\n# Stop tracing and save logs to JSON\\ntracing.stop()\\n```\\n\\nYou can then parse the trace data and visualize it using libraries like `networkx` or `matplotlib`.\\n\\n---\\n\\n### **Knowledge Graphs with LLMs**\\nIf you want to build **knowledge graphs** using LLMs (e.g., extracting entities or relationships from text), you can combine LangChain with graph databases like Neo4j or tools like **NLTK** for NLP tasks. Here’s an example:\\n\\n#### **Example Workflow: Extract entities and build a graph:**\\n```python\\nfrom langchain import LLMChain\\nfrom langchain.llms import OpenAI\\n\\nllm = OpenAI(temperature=0.0)\\nprompt = \"\"\"\\nExtract entities and relationships from the following text:\\n{text}\\n\\nReturn in format: [[Entity1, Entity2, Relationship]]\\n\"\"\"\\n\\nchain = LLMChain(llm=llm, prompt=prompt)\\n\\nresult = chain.run(\"Elon Musk founded Tesla and SpaceX.\")\\nentities = result.strip().strip(\"[]\").split(\", \")\\n\\n# Now, use a graph database (e.g., Neo4j) to store the entities and relationships\\n```\\n\\n---\\n\\n### **Common Use Cases for \"LangGraph-like\" Tools**\\n1. **Debugging Chains:** Visualizing complex chains to ensure data flows correctly.\\n2. **Knowledge Graphs:** Using LLMs to extract relationships and build graphs.\\n3. **Workflow Optimization:** Mapping out multi-step processes to identify bottlenecks.\\n\\n---\\n\\n### **Further Resources**\\n- **LangChain Documentation**: [LangChain Official Docs](https://python.langchain.com/docs/)\\n- **Graph Visualization**: [Graphviz](https://graphviz.org/), [NetworkX](https://networkx.org/)\\n\\nIf you have a specific task or question in mind (e.g., \"How to visualize a LangChain chain as a graph\"), share more details, and I can provide tailored guidance!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1697, 'prompt_tokens': 13, 'total_tokens': 1710, 'completion_time': 3.999842653, 'prompt_time': 0.004862438, 'queue_time': 0.179135151, 'total_time': 4.004705091}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_a91d9c2cfb', 'finish_reason': 'stop', 'logprobs': None}, id='run--75db3677-cbc8-479b-9089-4db4d4bbe399-0', usage_metadata={'input_tokens': 13, 'output_tokens': 1697, 'total_tokens': 1710})}])\n",
            "content='\\n<think>\\nOkay, the user mentioned \"LAnggraph.\" I think they might be referring to LangGraph, which I know is related to LangChain. Let me confirm that first. LangChain is a framework for developing applications using LLMs. LangGraph, perhaps, is a tool within LangChain for visualizing the structure of the chains or the data flow? I should check the official documentation or look up recent updates to see if there\\'s a specific tool called LangGraph.\\n\\nAlternatively, maybe it\\'s a typo or a less commonly known term. Let me think of possibilities. Could it be a part of the LangChain library that handles graph-based data structures or workflows? Or maybe it\\'s a tool for creating graphs of model interactions? I\\'ve heard of tools like LLMs in a graph format for knowledge graphs, but I\\'m not sure.\\n\\nWait, maybe LangGraph is a visualization tool for LangChain chains. The user might be asking how to use it or what it does. Since LangChain allows creating chains of LLMs and other components, visualizing these chains could help in debugging or understanding the flow. If that\\'s the case, I should explain how to use LangGraph, perhaps through code examples or by directing them to the relevant documentation.\\n\\nAlternatively, if LangGraph isn\\'t a standard part of LangChain, maybe the user is referring to a different project. I should consider that possibility as well. Maybe a quick search would help, but since I can\\'t browse the internet, I have to rely on existing knowledge. I recall that LangChain has a Chains module, and sometimes they mention visualization. There\\'s also a tool called \"Trace\" in LangChain for tracing runs, which might be related to graphing.\\n\\nLet me structure the response. First, clarify that LangGraph might be part of LangChain\\'s visualization tools. Then explain LangChain\\'s purpose, mention Chains, and then discuss how to visualize them using LangChain\\'s built-in features or third-party tools. If there\\'s no LangGraph, perhaps suggest alternatives like using graphviz or generating DOT files from the chain structure.\\n\\nWait, maybe the user is confused between LangChain and LangGraph, thinking they\\'re separate. I should correct that LangChain is the main framework, and visualization tools like graphviz can be used alongside it. Alternatively, maybe they are referring to a specific tool called LangGraph that I\\'m not aware of. In that case, I should mention that it\\'s not part of the standard LangChain package and suggest checking the LangChain documentation or community resources for more info.\\n\\nI should also consider if the user is looking for an explanation of what LangGraph is. If it\\'s a tool for creating knowledge graphs with LLMs, then I can explain how to use LangChain with knowledge graphs. But without more context, it\\'s a bit tricky. The best approach is to outline possible scenarios: LangGraph as part of LangChain\\'s visualization, a separate tool, or a misunderstanding. Then provide general guidance on visualizing workflows, knowledge graphs, or debugging chains in LangChain.\\n\\nAlso, include code examples if possible. For instance, showing how to create a chain and then visualize its steps. Maybe using matplotlib or networkx to draw the graph structure of a chain. Alternatively, using LangChain\\'s trace and view it in the UI. Let me think of a sample code snippet for a simple chain and then a way to represent it as a graph.\\n\\nAlternatively, check if there\\'s a method in LangChain to export the chain structure to a graph format. The user might be looking for that. If not, suggest alternatives. Make sure to mention that if they have a specific question or task related to LangGraph, they should provide more details so I can assist better.\\n\\nAnother angle: Maybe \"LangGraph\" refers to a specific implementation or a fork of LangChain with graph capabilities. Since I can\\'t verify, I should stick to known information and suggest possible approaches. Conclude by inviting them to clarify if needed.\\n</think>\\n\\nIt seems like you might be referring to **LangChain**, a framework for developing applications with Large Language Models (LLMs), or possibly a visualization tool related to it. The term \"LangGraph\" isn’t a widely recognized term in the context of LangChain, but I can help clarify how to work with **graphs or visualizations** in the LangChain ecosystem.\\n\\n---\\n\\n### **If you meant \"LangChain\":**\\nLangChain is a library for developing applications using LLMs, with a focus on structuring workflows, managing data, and building complex LLM pipelines. It includes tools like **chains**, **agents**, and **memory**, which can be visualized to understand their flow.\\n\\n---\\n\\n### **Visualizing Chains (LangChain)**\\nLangChain itself doesn’t have a built-in tool called \"LangGraph,\" but you can visualize the structure of **chains** (sequences of LLM operations) using standard visualization libraries. Here’s how:\\n\\n#### **1. Using `graphviz` for workflow diagrams:**\\nYou can manually create a graph of your LangChain chain using tools like `graphviz` (DOT language) to represent nodes (LLM steps) and edges (data flow).\\n\\n**Example:**\\n```python\\nfrom graphviz import Digraph\\n\\ndot = Digraph(comment=\\'LangChain Workflow\\')\\n\\n# Add nodes for each component in your chain\\ndot.node(\\'LLM1\\', \\'Text Generation\\')\\ndot.node(\\'LLM2\\', \\'Summarization\\')\\ndot.node(\\'Output\\', \\'Final Output\\')\\n\\n# Connect components\\ndot.edge(\\'LLM1\\', \\'LLM2\\', label=\\'Input Data\\')\\ndot.edge(\\'LLM2\\', \\'Output\\', label=\\'Summary\\')\\n\\nprint(dot.source)\\ndot.render(\\'chain_graph.dot\\', view=True)\\n```\\n\\n#### **2. Using LangChain’s built-in tracing:**\\nLangChain provides a `Tracer` class to log and trace the execution of chains. You can then use the trace data to reconstruct the workflow graphically.\\n\\n```python\\nfrom langchain import tracing\\nfrom langchain.chains import LLMChain\\nfrom langchain.llms import OpenAI\\n\\n# Start tracing\\ntracing.set_handler(tracing.FileHandler())\\n\\n# Create a simple chain\\nllm = OpenAI(temperature=0.7)\\nchain = LLMChain(llm=llm, prompt=prompt_template)\\n\\n# Run the chain and log steps\\nchain.run(\"Input text\")\\n\\n# Stop tracing and save logs to JSON\\ntracing.stop()\\n```\\n\\nYou can then parse the trace data and visualize it using libraries like `networkx` or `matplotlib`.\\n\\n---\\n\\n### **Knowledge Graphs with LLMs**\\nIf you want to build **knowledge graphs** using LLMs (e.g., extracting entities or relationships from text), you can combine LangChain with graph databases like Neo4j or tools like **NLTK** for NLP tasks. Here’s an example:\\n\\n#### **Example Workflow: Extract entities and build a graph:**\\n```python\\nfrom langchain import LLMChain\\nfrom langchain.llms import OpenAI\\n\\nllm = OpenAI(temperature=0.0)\\nprompt = \"\"\"\\nExtract entities and relationships from the following text:\\n{text}\\n\\nReturn in format: [[Entity1, Entity2, Relationship]]\\n\"\"\"\\n\\nchain = LLMChain(llm=llm, prompt=prompt)\\n\\nresult = chain.run(\"Elon Musk founded Tesla and SpaceX.\")\\nentities = result.strip().strip(\"[]\").split(\", \")\\n\\n# Now, use a graph database (e.g., Neo4j) to store the entities and relationships\\n```\\n\\n---\\n\\n### **Common Use Cases for \"LangGraph-like\" Tools**\\n1. **Debugging Chains:** Visualizing complex chains to ensure data flows correctly.\\n2. **Knowledge Graphs:** Using LLMs to extract relationships and build graphs.\\n3. **Workflow Optimization:** Mapping out multi-step processes to identify bottlenecks.\\n\\n---\\n\\n### **Further Resources**\\n- **LangChain Documentation**: [LangChain Official Docs](https://python.langchain.com/docs/)\\n- **Graph Visualization**: [Graphviz](https://graphviz.org/), [NetworkX](https://networkx.org/)\\n\\nIf you have a specific task or question in mind (e.g., \"How to visualize a LangChain chain as a graph\"), share more details, and I can provide tailored guidance!' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 1697, 'prompt_tokens': 13, 'total_tokens': 1710, 'completion_time': 3.999842653, 'prompt_time': 0.004862438, 'queue_time': 0.179135151, 'total_time': 4.004705091}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_a91d9c2cfb', 'finish_reason': 'stop', 'logprobs': None} id='run--75db3677-cbc8-479b-9089-4db4d4bbe399-0' usage_metadata={'input_tokens': 13, 'output_tokens': 1697, 'total_tokens': 1710}\n",
            "Assisstant: \n",
            "<think>\n",
            "Okay, the user mentioned \"LAnggraph.\" I think they might be referring to LangGraph, which I know is related to LangChain. Let me confirm that first. LangChain is a framework for developing applications using LLMs. LangGraph, perhaps, is a tool within LangChain for visualizing the structure of the chains or the data flow? I should check the official documentation or look up recent updates to see if there's a specific tool called LangGraph.\n",
            "\n",
            "Alternatively, maybe it's a typo or a less commonly known term. Let me think of possibilities. Could it be a part of the LangChain library that handles graph-based data structures or workflows? Or maybe it's a tool for creating graphs of model interactions? I've heard of tools like LLMs in a graph format for knowledge graphs, but I'm not sure.\n",
            "\n",
            "Wait, maybe LangGraph is a visualization tool for LangChain chains. The user might be asking how to use it or what it does. Since LangChain allows creating chains of LLMs and other components, visualizing these chains could help in debugging or understanding the flow. If that's the case, I should explain how to use LangGraph, perhaps through code examples or by directing them to the relevant documentation.\n",
            "\n",
            "Alternatively, if LangGraph isn't a standard part of LangChain, maybe the user is referring to a different project. I should consider that possibility as well. Maybe a quick search would help, but since I can't browse the internet, I have to rely on existing knowledge. I recall that LangChain has a Chains module, and sometimes they mention visualization. There's also a tool called \"Trace\" in LangChain for tracing runs, which might be related to graphing.\n",
            "\n",
            "Let me structure the response. First, clarify that LangGraph might be part of LangChain's visualization tools. Then explain LangChain's purpose, mention Chains, and then discuss how to visualize them using LangChain's built-in features or third-party tools. If there's no LangGraph, perhaps suggest alternatives like using graphviz or generating DOT files from the chain structure.\n",
            "\n",
            "Wait, maybe the user is confused between LangChain and LangGraph, thinking they're separate. I should correct that LangChain is the main framework, and visualization tools like graphviz can be used alongside it. Alternatively, maybe they are referring to a specific tool called LangGraph that I'm not aware of. In that case, I should mention that it's not part of the standard LangChain package and suggest checking the LangChain documentation or community resources for more info.\n",
            "\n",
            "I should also consider if the user is looking for an explanation of what LangGraph is. If it's a tool for creating knowledge graphs with LLMs, then I can explain how to use LangChain with knowledge graphs. But without more context, it's a bit tricky. The best approach is to outline possible scenarios: LangGraph as part of LangChain's visualization, a separate tool, or a misunderstanding. Then provide general guidance on visualizing workflows, knowledge graphs, or debugging chains in LangChain.\n",
            "\n",
            "Also, include code examples if possible. For instance, showing how to create a chain and then visualize its steps. Maybe using matplotlib or networkx to draw the graph structure of a chain. Alternatively, using LangChain's trace and view it in the UI. Let me think of a sample code snippet for a simple chain and then a way to represent it as a graph.\n",
            "\n",
            "Alternatively, check if there's a method in LangChain to export the chain structure to a graph format. The user might be looking for that. If not, suggest alternatives. Make sure to mention that if they have a specific question or task related to LangGraph, they should provide more details so I can assist better.\n",
            "\n",
            "Another angle: Maybe \"LangGraph\" refers to a specific implementation or a fork of LangChain with graph capabilities. Since I can't verify, I should stick to known information and suggest possible approaches. Conclude by inviting them to clarify if needed.\n",
            "</think>\n",
            "\n",
            "It seems like you might be referring to **LangChain**, a framework for developing applications with Large Language Models (LLMs), or possibly a visualization tool related to it. The term \"LangGraph\" isn’t a widely recognized term in the context of LangChain, but I can help clarify how to work with **graphs or visualizations** in the LangChain ecosystem.\n",
            "\n",
            "---\n",
            "\n",
            "### **If you meant \"LangChain\":**\n",
            "LangChain is a library for developing applications using LLMs, with a focus on structuring workflows, managing data, and building complex LLM pipelines. It includes tools like **chains**, **agents**, and **memory**, which can be visualized to understand their flow.\n",
            "\n",
            "---\n",
            "\n",
            "### **Visualizing Chains (LangChain)**\n",
            "LangChain itself doesn’t have a built-in tool called \"LangGraph,\" but you can visualize the structure of **chains** (sequences of LLM operations) using standard visualization libraries. Here’s how:\n",
            "\n",
            "#### **1. Using `graphviz` for workflow diagrams:**\n",
            "You can manually create a graph of your LangChain chain using tools like `graphviz` (DOT language) to represent nodes (LLM steps) and edges (data flow).\n",
            "\n",
            "**Example:**\n",
            "```python\n",
            "from graphviz import Digraph\n",
            "\n",
            "dot = Digraph(comment='LangChain Workflow')\n",
            "\n",
            "# Add nodes for each component in your chain\n",
            "dot.node('LLM1', 'Text Generation')\n",
            "dot.node('LLM2', 'Summarization')\n",
            "dot.node('Output', 'Final Output')\n",
            "\n",
            "# Connect components\n",
            "dot.edge('LLM1', 'LLM2', label='Input Data')\n",
            "dot.edge('LLM2', 'Output', label='Summary')\n",
            "\n",
            "print(dot.source)\n",
            "dot.render('chain_graph.dot', view=True)\n",
            "```\n",
            "\n",
            "#### **2. Using LangChain’s built-in tracing:**\n",
            "LangChain provides a `Tracer` class to log and trace the execution of chains. You can then use the trace data to reconstruct the workflow graphically.\n",
            "\n",
            "```python\n",
            "from langchain import tracing\n",
            "from langchain.chains import LLMChain\n",
            "from langchain.llms import OpenAI\n",
            "\n",
            "# Start tracing\n",
            "tracing.set_handler(tracing.FileHandler())\n",
            "\n",
            "# Create a simple chain\n",
            "llm = OpenAI(temperature=0.7)\n",
            "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
            "\n",
            "# Run the chain and log steps\n",
            "chain.run(\"Input text\")\n",
            "\n",
            "# Stop tracing and save logs to JSON\n",
            "tracing.stop()\n",
            "```\n",
            "\n",
            "You can then parse the trace data and visualize it using libraries like `networkx` or `matplotlib`.\n",
            "\n",
            "---\n",
            "\n",
            "### **Knowledge Graphs with LLMs**\n",
            "If you want to build **knowledge graphs** using LLMs (e.g., extracting entities or relationships from text), you can combine LangChain with graph databases like Neo4j or tools like **NLTK** for NLP tasks. Here’s an example:\n",
            "\n",
            "#### **Example Workflow: Extract entities and build a graph:**\n",
            "```python\n",
            "from langchain import LLMChain\n",
            "from langchain.llms import OpenAI\n",
            "\n",
            "llm = OpenAI(temperature=0.0)\n",
            "prompt = \"\"\"\n",
            "Extract entities and relationships from the following text:\n",
            "{text}\n",
            "\n",
            "Return in format: [[Entity1, Entity2, Relationship]]\n",
            "\"\"\"\n",
            "\n",
            "chain = LLMChain(llm=llm, prompt=prompt)\n",
            "\n",
            "result = chain.run(\"Elon Musk founded Tesla and SpaceX.\")\n",
            "entities = result.strip().strip(\"[]\").split(\", \")\n",
            "\n",
            "# Now, use a graph database (e.g., Neo4j) to store the entities and relationships\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "### **Common Use Cases for \"LangGraph-like\" Tools**\n",
            "1. **Debugging Chains:** Visualizing complex chains to ensure data flows correctly.\n",
            "2. **Knowledge Graphs:** Using LLMs to extract relationships and build graphs.\n",
            "3. **Workflow Optimization:** Mapping out multi-step processes to identify bottlenecks.\n",
            "\n",
            "---\n",
            "\n",
            "### **Further Resources**\n",
            "- **LangChain Documentation**: [LangChain Official Docs](https://python.langchain.com/docs/)\n",
            "- **Graph Visualization**: [Graphviz](https://graphviz.org/), [NetworkX](https://networkx.org/)\n",
            "\n",
            "If you have a specific task or question in mind (e.g., \"How to visualize a LangChain chain as a graph\"), share more details, and I can provide tailored guidance!\n",
            "user :q\n",
            "Good bye ..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wNnuzMlYSFPo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}